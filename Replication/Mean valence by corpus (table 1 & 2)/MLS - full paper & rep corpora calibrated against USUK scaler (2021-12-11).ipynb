{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLS pandas - Apply USUK scaler to full newspaper corpora & national representative corpora (2021-12-10)\n",
    "\n",
    "_by A. Maurits van der Veen_  \n",
    "\n",
    "_Modification history:_  \n",
    "_2021-12-03 - Convert to csv lexica; use newest versions of lexica, as publicly available_  \n",
    "_2021-12-10 - Clean up & streamline for GitHub repo_  \n",
    "_2021-12-11 - Applied to representative corpora_  \n",
    "\n",
    "__Note: This is for tables 1&2 in the MLS method paper__\n",
    "\n",
    "The files used here are too large for Github. They can be found on Zenodo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Set-up\n",
    "\n",
    "Import necessary code modules; specify location of sentiment analysis lexica and associated files; specify corpus location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectfolder = '/Users/xxx/Replication/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using python version 3.10.12.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# import os\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Print summary version info (for fuller info, simply print sys.version)\n",
    "print('You are using python version {}.'.format(sys.version.split()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "repcorpusfolder = projectfolder + 'Mean valence by corpus (table 1 & 2)/'\n",
    "\n",
    "calibratedsuffix = '_vals_cal.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get mean valence for 3-year periods for 2 US & 2 UK papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 3-year combined corpora: 1993-1995, 2001-2004, 2008-2010, 2016-2018\n",
    "yearranges = {'1993-1995': (1993, 1994, 1995),\n",
    "              '2001-2003': (2001, 2002, 2003),\n",
    "              '2008-2010': (2008, 2009, 2010),\n",
    "              '2016-2018': (2016, 2017, 2018)}\n",
    "\n",
    "corpusnames = [yearrange for yearrange, years in yearranges.items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean corpus valence (over 113705 articles) for Mail, 1993-1995: -0.236\n",
      "Mean corpus valence (over 159984 articles) for Mail, 2001-2003: -0.221\n",
      "Mean corpus valence (over 202058 articles) for Mail, 2008-2010: -0.172\n",
      "Mean corpus valence (over 126349 articles) for Mail, 2016-2018: -0.255\n",
      "Mean corpus valence (over 37814 articles) for Observer, 1993-1995: -0.129\n",
      "Mean corpus valence (over 54634 articles) for Observer, 2001-2003: -0.070\n",
      "Mean corpus valence (over 86303 articles) for Observer, 2008-2010: 0.077\n",
      "Mean corpus valence (over 21507 articles) for Observer, 2016-2018: 0.022\n",
      "Mean corpus valence (over 47409 articles) for Sunday Times, 1993-1995: -0.071\n",
      "Mean corpus valence (over 75459 articles) for Sunday Times, 2001-2003: 0.024\n",
      "Mean corpus valence (over 139445 articles) for Sunday Times, 2008-2010: 0.050\n",
      "Mean corpus valence (over 130349 articles) for Sunday Times, 2016-2018: 0.195\n",
      "Mean corpus valence (over 93365 articles) for USA Today, 1993-1995: -0.079\n",
      "Mean corpus valence (over 65672 articles) for USA Today, 2001-2003: -0.045\n",
      "Mean corpus valence (over 53933 articles) for USA Today, 2008-2010: 0.054\n",
      "Mean corpus valence (over 38061 articles) for USA Today, 2016-2018: 0.070\n"
     ]
    }
   ],
   "source": [
    "# Get the mean valence & article count\n",
    "\n",
    "for paper in ['Mail', 'Observer', 'Sunday Times', 'USA Today']:\n",
    "    for yearrange in ['1993-1995', '2001-2003', '2008-2010', '2016-2018']:\n",
    "    \n",
    "       valencefile = repcorpusfolder + paper + '/' + yearrange + calibratedsuffix\n",
    "       df = pd.read_csv(valencefile, index_col=False)\n",
    "       print('Mean corpus valence (over {} articles) for {}, {}: {:5.3f}'.format(len(df), paper, yearrange, df['avg_valence'].mean()))\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get mean valence for representative corpora\n",
    "\n",
    "The search and collection criteria for these corpora are described in the supplementary info for the paper.\n",
    "MLS sentiment analysis and calibration steps were applied to each corpus. Here we simply calculated information about the \n",
    "average calibrated valence for each corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean corpus valence (over 48283 articles) for US: 0.018\n",
      "Mean corpus valence (over 59404 articles) for UK: -0.014\n",
      "Mean corpus valence (over 22860 articles) for CA: 0.014\n",
      "Mean corpus valence (over 24114 articles) for AU: 0.132\n",
      "Mean corpus valence (over 7455 articles) for NZ: 0.136\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for repcorpus in ['US', 'UK', 'CA', 'AU', 'NZ']:\n",
    "    valencefile = repcorpusfolder + repcorpus + calibratedsuffix\n",
    "    df = pd.read_csv(valencefile, index_col=False)\n",
    "    print('Mean corpus valence (over {} articles) for {}: {:5.3f}'.format(len(df), repcorpus, df['avg_valence'].mean()))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
