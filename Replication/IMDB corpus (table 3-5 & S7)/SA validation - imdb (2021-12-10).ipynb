{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA validation - imdb (2021-12-10)\n",
    "\n",
    "_by A. Maurits van der Veen_  \n",
    "_modification history:_  \n",
    "_2018-11-01 - Initial clean-up; prep for bootstrapping_  \n",
    "_2020-06-10 - Update to include negation processing_  \n",
    "_2021-12-01 - Compare newer versions of lexica to older ones_  \n",
    "\n",
    "Tests of MLS sentiment analysis approach against the imdb 'gold standard' corpus.\n",
    "Some pathnames may need to be adjusted to make this work, but all the files are available in the MLS Github repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectfolder = '/Users/xxx/Replication/'\n",
    "corpusfilestem = projectfolder + 'IMDB corpus (table 3-5 & S7)/imdb'  # extension: '_valencedata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using python version 3.10.12.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(projectfolder + 'Code')  \n",
    "import sentiment_eval\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Print summary version info (for fuller info, simply print sys.version)\n",
    "print('You are using python version {}.'.format(sys.version.split()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scaler_fromcsv(filename, featurenames=(), includevar=False, displayinfo=True):\n",
    "    \"\"\"Load a calibration scaler from a text file\n",
    "\n",
    "    Textfile will contain:\n",
    "    - header line, containing scaler name, number of observations seen,\n",
    "      number of features (N), standard deviation adjustment, and descriptor string\n",
    "    - N rows of feature information, containing name, mean, standard deviation, and variance (if includevar)\n",
    "\n",
    "    Function returns sklearn StandardScaler object,\n",
    "                     number of features used, number of features available,\n",
    "                     standard deviation adjustment, and descriptor\n",
    "\n",
    "    If displayinfo is True, print information about the contents of the scaler before returning\n",
    "\n",
    "    Note that the standard deviation adjustment is valid only if all features are used\n",
    "    (i.e. number of features used == number of features available)\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Read data from file\n",
    "    with open(filename, 'r', encoding='utf-8', errors='ignore') as scalerfile:\n",
    "        scalercsv = csv.reader(scalerfile)\n",
    "\n",
    "        # Read & parse header\n",
    "        headerrow = next(scalercsv)\n",
    "        name = headerrow[0]\n",
    "        nrfeatures = int(headerrow[2])\n",
    "        stdev_adj = float(headerrow[3])\n",
    "        descriptor = headerrow[4]\n",
    "\n",
    "        # Read & parse individual features\n",
    "        nrfeaturesused = 0\n",
    "        featuresused, means, stdevs, variances = [], [], [], []\n",
    "        for row in scalercsv:\n",
    "            if len(featurenames) == 0 or (len(featurenames) > 0 and row[0] in featurenames):\n",
    "                featuresused.append(row[0])\n",
    "                nrfeaturesused += 1\n",
    "                means.append(float(row[1]))\n",
    "                stdevs.append(float(row[2]))\n",
    "                if includevar:\n",
    "                    variances.append(float(row[3]))\n",
    "\n",
    "    # Initialize scaler\n",
    "    newscaler = StandardScaler()\n",
    "    newscaler.n_samples_seen_ = int(headerrow[1])\n",
    "    newscaler.mean_ = np.array(means)\n",
    "    newscaler.scale_ = np.array(stdevs)\n",
    "    newscaler.var_ = np.array(variances)\n",
    "\n",
    "    if displayinfo:\n",
    "        print(\"Descriptor:\", descriptor)\n",
    "        print(\"Lexica used ({}): {}\".format(nrfeaturesused, featuresused))\n",
    "        print(\"Means:\", newscaler.mean_)\n",
    "        print(\"Std. devs.:\", newscaler.scale_)\n",
    "        print(\"Std. dev. of average across lexica (calculated using {} lexica): {}\".format(nrfeatures, stdev_adj))\n",
    "\n",
    "    return newscaler, featuresused, nrfeaturesused, nrfeatures, stdev_adj, descriptor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify negaters\n",
    "\n",
    "# The standard SO-CAL list (we derive our modification/intensification approach from them):\n",
    "# [\"not\", \"no\", \"n't\", \"neither\", \"nor\", \"nothing\", \"never\", \"none\", \n",
    "#  \"lack\", \"lacked\", \"lacking\", \"lacks\", \"missing\", \"without\", \"absence\", \"devoid\"]\n",
    "\n",
    "# In our standard list we do not include \"n't\" since we handle that in text preprocessing.\n",
    "# We do add 3 'no...' words that are also negating in effect. \n",
    "# In addition, we have added 'absence_of', 'devoid_of' and 'lack_of' to our modifier dictionary\n",
    "negaters = ('not', 'no', 'neither', 'nor', 'nothing', 'never', 'none', \n",
    "            'nowhere', 'noone', 'nobody',\n",
    "            'lack', 'lacked', 'lacking', 'lacks', 'missing', 'without')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration file pathnames (include extension)\n",
    "\n",
    "SAfolder = projectfolder + 'Github/MultiLexScaled/'\n",
    "calibrationfolder = SAfolder + 'Scalers/'\n",
    "\n",
    "calibrationfile_US = calibrationfolder + 'Calibration_US_2021-12-10.csv'\n",
    "calibrationfile_UK = calibrationfolder + 'Calibration_UK_2021-12-10.csv'\n",
    "calibrationfile_USUK = calibrationfolder + 'Calibration_USUK_2021-12-10.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify lexica\n",
    "\n",
    "lexica = {'HuLiu':          SAfolder + 'HuLiu/opinion-lexicon-English/HuLiu_lexiconX.csv',\n",
    "          'LabMT_filtered': SAfolder + 'labMT/labMT_lexicon_filtered.csv',\n",
    "          'LexicoderSD':    SAfolder + 'Lexicoder/LSDaug2015/LSD_lexiconX.csv',\n",
    "          'MPQA':           SAfolder + 'MPQA 2.0/opinionfinderv2.0/lexicons/MPQA_lexicon.csv',\n",
    "          'NRC':            SAfolder + 'NRC/NRC-Emotion-Lexicon-v0.92/NRC_lexicon.csv',\n",
    "          'SOCAL':          SAfolder + 'SO-CAL/English (from GitHub)/SO-CAL_lexiconX.csv',\n",
    "          'SWN_filtered':   SAfolder + 'SWN/SWN_lexicon_filtered0.1.csv',\n",
    "          'WordStat':       SAfolder + 'WordStat/WSD 2.0/WordStat_lexicon2X.csv',\n",
    "         } \n",
    "lexnames = sorted(lexica.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptor: New scaler for US based on 48283 texts. Generated: 2021-12-10 11:12:39.832747\n",
      "Lexica used (8): ['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "Means: [ 3.33755708e-03  1.89320002e-01  1.21356846e-02  7.69971106e-03\n",
      "  2.26526518e-02  3.71012146e-02  1.27342660e-03 -1.64595405e-04]\n",
      "Std. devs.: [0.01931773 0.08943294 0.02625014 0.01699521 0.02416683 0.05037926\n",
      " 0.00624028 0.03290689]\n",
      "Std. dev. of average across lexica (calculated using 8 lexica): 0.8486667938382454\n",
      "\n",
      "US means: [ 3.33755708e-03  1.89320002e-01  1.21356846e-02  7.69971106e-03\n",
      "  2.26526518e-02  3.71012146e-02  1.27342660e-03 -1.64595405e-04]\n",
      "US stdevs: [0.01931773 0.08943294 0.02625014 0.01699521 0.02416683 0.05037926\n",
      " 0.00624028 0.03290689]\n",
      "US final stdev: 0.8486667938382454 \n",
      "\n",
      "Descriptor: New scaler for UK based on 59404 texts. Generated: 2021-12-10 21:21:26.618950\n",
      "Lexica used (8): ['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "Means: [ 0.00260408  0.18669727  0.01144086  0.00763158  0.01968383  0.03819822\n",
      "  0.00137731 -0.00186231]\n",
      "Std. devs.: [0.02502675 0.09296783 0.03025498 0.02170503 0.02676847 0.06477786\n",
      " 0.00784905 0.03723254]\n",
      "Std. dev. of average across lexica (calculated using 8 lexica): 0.8509973852076198\n",
      "\n",
      "UK means: [ 0.00260408  0.18669727  0.01144086  0.00763158  0.01968383  0.03819822\n",
      "  0.00137731 -0.00186231]\n",
      "UK stdevs: [0.02502675 0.09296783 0.03025498 0.02170503 0.02676847 0.06477786\n",
      " 0.00784905 0.03723254]\n",
      "UK final stdev: 0.8509973852076198 \n",
      "\n",
      "Descriptor: New scaler for US UK corpus based on 107687 texts. Generated: 2021-12-10 21:39:38.001915\n",
      "Lexica used (8): ['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "Means: [ 0.00293294  0.18787321  0.01175239  0.00766213  0.02101494  0.03770636\n",
      "  0.00133073 -0.00110112]\n",
      "Std. devs.: [0.02264866 0.09140913 0.02853105 0.01973286 0.02567715 0.05876253\n",
      " 0.00717268 0.03536866]\n",
      "Std. dev. of average across lexica (calculated using 8 lexica): 0.8495984756427533\n",
      "\n",
      "USUK means: [ 0.00293294  0.18787321  0.01175239  0.00766213  0.02101494  0.03770636\n",
      "  0.00133073 -0.00110112]\n",
      "USUK stdevs: [0.02264866 0.09140913 0.02853105 0.01973286 0.02567715 0.05876253\n",
      " 0.00717268 0.03536866]\n",
      "USUK final stdev: 0.8495984756427533 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify means & standard deviation data used in calibration, by extracting from the calibraton files\n",
    "\n",
    "neutralscaler_US, featurenames, nrfeatures, nravailable, stdev_adj_US, descriptor = \\\n",
    "        load_scaler_fromcsv(calibrationfile_US, includevar=True, displayinfo=True)\n",
    "USm = neutralscaler_US.mean_\n",
    "USs = neutralscaler_US.scale_\n",
    "print('\\nUS means:', USm)\n",
    "print('US stdevs:', USs)\n",
    "print('US final stdev:', stdev_adj_US, '\\n')\n",
    "\n",
    "neutralscaler_UK, featurenames, nrfeatures, nravailable, stdev_adj_UK, descriptor = \\\n",
    "        load_scaler_fromcsv(calibrationfile_UK, includevar=True, displayinfo=True)\n",
    "UKm = neutralscaler_UK.mean_\n",
    "UKs = neutralscaler_UK.scale_\n",
    "print('\\nUK means:', UKm)\n",
    "print('UK stdevs:', UKs)\n",
    "print('UK final stdev:', stdev_adj_UK, '\\n')\n",
    "\n",
    "neutralscaler_USUK, featurenames, nrfeatures, nravailable, stdev_adj_USUK, descriptor = \\\n",
    "        load_scaler_fromcsv(calibrationfile_USUK, includevar=True, displayinfo=True)\n",
    "USUKm = neutralscaler_USUK.mean_\n",
    "USUKs = neutralscaler_USUK.scale_\n",
    "print('\\nUSUK means:', USUKm)\n",
    "print('USUK stdevs:', USUKs)\n",
    "print('USUK final stdev:', stdev_adj_USUK, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Performance analysis: imdb\n",
    "\n",
    "We have calculated valence using MLS for 4 different conditions: no modifiers, negators only, intensifiers only, and 'standard' (both negators and intensifiers). This allows us to compare how these compare relative to one another.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valencefile_combined = corpusfilestem + '_valencedata.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Assess performance of individual lexica & different scalers\n",
    "\n",
    "Measure classification performance using cuts at:\n",
    "- 0\n",
    "- optimal for this lexicon (& given neg/mod setting)\n",
    "- sets of specified cut-points \n",
    "  (US 1996-2015, UK translated 1996-2015, USUK)\n",
    "  \n",
    "Compare results for the translated & untranslated imdb data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different SA parameters\n",
    "jobspeclist = [('', True, negaters),\n",
    "               ('_negonly', False, negaters),\n",
    "               ('_modsonly', True, ()),\n",
    "               ('_none', False, ())]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This output is for tables 3 & 4 in the paper, plus S7 in the supplementary info.\n",
    "\n",
    "Individual lexica in the first table; fourth, fifth, and first data columns for our calibration, corpus calibration, and optimal calibration, respectively.\n",
    "\n",
    "Overall performance, use the USUK averaging. Note that using US averaging gets marginally better results -- perhaps  because most of the movie reviews written by Americans?!\n",
    "\n",
    "For performance in sets of articles (table 3), use the USUK averaging too.\n",
    "\n",
    "For the appendix, look at the job specs `negonly` and `none`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********* Working on jobspec: ('', True, ('not', 'no', 'neither', 'nor', 'nothing', 'never', 'none', 'nowhere', 'noone', 'nobody', 'lack', 'lacked', 'lacking', 'lacks', 'missing', 'without'))\n",
      "Working with 25000 negative and 25000 positive texts.\n",
      "\n",
      "Results for selected data\n",
      "By measure, showing performance (cut-point), in order: optimal, US, UK, USUK, corpus\n",
      "percent correct                    HuLiu: 74.33(0.000); 73.99(0.003); 74.01(0.003); 74.00(0.003); 73.94(0.002)\n",
      "percent correct           LabMT_filtered: 69.59(0.221); 68.10(0.189); 67.84(0.187); 67.97(0.188); 69.55(0.219)\n",
      "percent correct              LexicoderSD: 72.76(0.010); 72.57(0.012); 72.67(0.011); 72.61(0.012); 72.59(0.008)\n",
      "percent correct                     MPQA: 71.23(0.011); 71.08(0.008); 71.09(0.008); 71.10(0.008); 71.14(0.009)\n",
      "percent correct                      NRC: 69.72(0.013); 68.39(0.023); 69.15(0.020); 68.82(0.021); 69.62(0.012)\n",
      "percent correct                    SOCAL: 78.25(0.033); 78.16(0.037); 78.13(0.038); 78.13(0.038); 78.18(0.035)\n",
      "percent correct             SWN_filtered: 69.64(0.003); 69.06(0.001); 69.08(0.001); 69.06(0.001); 69.60(0.004)\n",
      "percent correct                 WordStat: 73.80(-0.004); 73.53(-0.000); 73.60(-0.002); 73.60(-0.001); 73.71(-0.007)\n",
      "\n",
      "*** Averaging using set of means: US ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 75.71(0.000); cut (mean): 75.70(-0.006); cut (opt): 75.76(-0.042)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 18482, mean 1.45, max 10.08, stdev 1.13, rating 8.9, length 216.57\n",
      "Label 0 & -ve: nr 19370, mean -1.34, min -15.21, stdev 1.02, rating 2.1, length 236.32\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 5630, mean 0.69, max 5.29, stdev 0.63, rating 2.6, length 213.56\n",
      "Label 1 but -ve: nr 6518, mean -0.77, min -5.57, stdev 0.68, rating 8.5, length 283.67\n",
      "\n",
      "Bootstrapping: 1000 draws of 1000 observations of sets of 1, 3, 6, 10, 12, 15, 25 texts at a time.\n",
      "\n",
      "Selecting from negative reviews\n",
      "Combining 1\n",
      "Combining 3\n",
      "Combining 6\n",
      "Combining 10\n",
      "Combining 12\n",
      "Combining 15\n",
      "Combining 25\n",
      "\n",
      "Selecting from positive reviews\n",
      "Combining 1\n",
      "Combining 3\n",
      "Combining 6\n",
      "Combining 10\n",
      "Combining 12\n",
      "Combining 15\n",
      "Combining 25\n",
      "\n",
      "Fractions correct for bootstrapping random sets of reviews - neg, pos, combined\n",
      "1 (0.7755369999999999, 0.749, 0.803) (0.740255, 0.714, 0.767) (0.7578959999999999, 0.718, 0.797)\n",
      "3 (0.897768, 0.878, 0.916) (0.865847, 0.844, 0.885) (0.8818075, 0.847, 0.914)\n",
      "6 (0.9621490000000001, 0.95, 0.974) (0.9405650000000001, 0.926, 0.955) (0.951357, 0.928, 0.972)\n",
      "10 (0.9886929999999999, 0.982, 0.995) (0.9781449999999999, 0.968, 0.987) (0.9834189999999998, 0.97, 0.994)\n",
      "12 (0.9938790000000001, 0.989, 0.998) (0.986173, 0.978, 0.993) (0.9900260000000001, 0.98, 0.998)\n",
      "15 (0.997253, 0.993, 1.0) (0.993169, 0.988, 0.998) (0.9952110000000001, 0.989, 1.0)\n",
      "25 (0.999839, 0.999, 1.0) (0.9992300000000002, 0.997, 1.0) (0.9995345, 0.997, 1.0)\n",
      "\n",
      "*** Averaging using set of means: UK ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 75.65(0.000); cut (mean): 75.66(0.019); cut (opt): 75.69(0.026)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 18654, mean 1.21, max 8.35, stdev 0.94, rating 8.9, length 217.13\n",
      "Label 0 & -ve: nr 19168, mean -1.10, min -12.52, stdev 0.84, rating 2.1, length 236.31\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 5832, mean 0.58, max 4.38, stdev 0.53, rating 2.6, length 214.39\n",
      "Label 1 but -ve: nr 6346, mean -0.63, min -4.47, stdev 0.56, rating 8.5, length 283.84\n",
      "\n",
      "Bootstrapping: 1000 draws of 1000 observations of sets of 1, 3, 6, 10, 12, 15, 25 texts at a time.\n",
      "\n",
      "Selecting from negative reviews\n",
      "Combining 1\n",
      "Combining 3\n",
      "Combining 6\n",
      "Combining 10\n",
      "Combining 12\n",
      "Combining 15\n",
      "Combining 25\n",
      "\n",
      "Selecting from positive reviews\n",
      "Combining 1\n",
      "Combining 3\n",
      "Combining 6\n",
      "Combining 10\n",
      "Combining 12\n",
      "Combining 15\n",
      "Combining 25\n",
      "\n",
      "Fractions correct for bootstrapping random sets of reviews - neg, pos, combined\n",
      "1 (0.7660399999999999, 0.74, 0.792) (0.74576, 0.718, 0.772) (0.7559, 0.724, 0.788)\n",
      "3 (0.889279, 0.869, 0.908) (0.8725470000000001, 0.853, 0.892) (0.8809130000000001, 0.857, 0.905)\n",
      "6 (0.9565240000000002, 0.944, 0.969) (0.946458, 0.932, 0.961) (0.951491, 0.934, 0.967)\n",
      "10 (0.986105, 0.978, 0.993) (0.981078, 0.972, 0.989) (0.9835915, 0.973, 0.992)\n",
      "12 (0.9918429999999999, 0.986, 0.997) (0.9883030000000002, 0.981, 0.994) (0.990073, 0.982, 0.996)\n",
      "15 (0.996455, 0.992, 0.999) (0.9945519999999999, 0.99, 0.999) (0.9955035, 0.991, 0.999)\n",
      "25 (0.999739, 0.998, 1.0) (0.9994900000000001, 0.998, 1.0) (0.9996145000000001, 0.998, 1.0)\n",
      "\n",
      "*** Averaging using set of means: USUK ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 75.68(0.000); cut (mean): 75.67(0.008); cut (opt): 75.71(-0.010)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 18576, mean 1.30, max 8.98, stdev 1.01, rating 8.9, length 216.91\n",
      "Label 0 & -ve: nr 19264, mean -1.19, min -13.52, stdev 0.91, rating 2.1, length 236.32\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 5736, mean 0.62, max 4.72, stdev 0.57, rating 2.6, length 213.97\n",
      "Label 1 but -ve: nr 6424, mean -0.68, min -4.87, stdev 0.60, rating 8.5, length 283.66\n",
      "\n",
      "Bootstrapping: 1000 draws of 1000 observations of sets of 1, 3, 6, 10, 12, 15, 25 texts at a time.\n",
      "\n",
      "Selecting from negative reviews\n",
      "Combining 1\n",
      "Combining 3\n",
      "Combining 6\n",
      "Combining 10\n",
      "Combining 12\n",
      "Combining 15\n",
      "Combining 25\n",
      "\n",
      "Selecting from positive reviews\n",
      "Combining 1\n",
      "Combining 3\n",
      "Combining 6\n",
      "Combining 10\n",
      "Combining 12\n",
      "Combining 15\n",
      "Combining 25\n",
      "\n",
      "Fractions correct for bootstrapping random sets of reviews - neg, pos, combined\n",
      "1 (0.770449, 0.745, 0.797) (0.7425109999999999, 0.716, 0.769) (0.75648, 0.719, 0.792)\n",
      "3 (0.8936230000000002, 0.875, 0.912) (0.8694120000000001, 0.848, 0.89) (0.8815175000000001, 0.852, 0.908)\n",
      "6 (0.959275, 0.947, 0.972) (0.943368, 0.929, 0.958) (0.9513215, 0.931, 0.97)\n",
      "10 (0.987426, 0.98, 0.994) (0.979664, 0.97, 0.987) (0.983545, 0.972, 0.993)\n",
      "12 (0.9929150000000001, 0.988, 0.998) (0.98741, 0.98, 0.994) (0.9901625000000002, 0.981, 0.997)\n",
      "15 (0.996868, 0.993, 1.0) (0.9938619999999999, 0.989, 0.998) (0.995365, 0.989, 0.999)\n",
      "25 (0.9997999999999999, 0.999, 1.0) (0.9993540000000001, 0.997, 1.0) (0.999577, 0.998, 1.0)\n",
      "\n",
      "*** Averaging using set of means: corpus ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 75.55(0.000); cut (mean): 75.55(0.000); cut (opt): 75.55(-0.000)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 18479, mean 0.81, max 5.58, stdev 0.63, rating 8.9, length 216.36\n",
      "Label 0 & -ve: nr 19295, mean -0.74, min -8.32, stdev 0.56, rating 2.1, length 236.68\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 5705, mean 0.39, max 2.94, stdev 0.36, rating 2.6, length 212.64\n",
      "Label 1 but -ve: nr 6521, mean -0.44, min -3.03, stdev 0.38, rating 8.5, length 284.23\n",
      "\n",
      "Bootstrapping: 1000 draws of 1000 observations of sets of 1, 3, 6, 10, 12, 15, 25 texts at a time.\n",
      "\n",
      "Selecting from negative reviews\n",
      "Combining 1\n",
      "Combining 3\n",
      "Combining 6\n",
      "Combining 10\n",
      "Combining 12\n",
      "Combining 15\n",
      "Combining 25\n",
      "\n",
      "Selecting from positive reviews\n",
      "Combining 1\n",
      "Combining 3\n",
      "Combining 6\n",
      "Combining 10\n",
      "Combining 12\n",
      "Combining 15\n",
      "Combining 25\n",
      "\n",
      "Fractions correct for bootstrapping random sets of reviews - neg, pos, combined\n",
      "1 (0.772313, 0.744, 0.799) (0.739124, 0.712, 0.766) (0.7557185000000001, 0.716, 0.795)\n",
      "3 (0.8943890000000001, 0.876, 0.913) (0.863791, 0.843, 0.885) (0.87909, 0.846, 0.909)\n",
      "6 (0.960157, 0.948, 0.971) (0.9396769999999999, 0.924, 0.953) (0.9499169999999999, 0.927, 0.97)\n",
      "10 (0.9877750000000001, 0.98, 0.994) (0.9775229999999999, 0.968, 0.987) (0.9826490000000001, 0.969, 0.993)\n",
      "12 (0.993135, 0.987, 0.997) (0.9857720000000001, 0.978, 0.993) (0.9894535, 0.979, 0.997)\n",
      "15 (0.9970429999999999, 0.993, 1.0) (0.99294, 0.987, 0.997) (0.9949915000000001, 0.988, 1.0)\n",
      "25 (0.999785, 0.999, 1.0) (0.9992170000000001, 0.997, 1.0) (0.9995010000000001, 0.998, 1.0)\n",
      "\n",
      "********* Working on jobspec: ('_negonly', False, ('not', 'no', 'neither', 'nor', 'nothing', 'never', 'none', 'nowhere', 'noone', 'nobody', 'lack', 'lacked', 'lacking', 'lacks', 'missing', 'without'))\n",
      "Working with 25000 negative and 25000 positive texts.\n",
      "\n",
      "Results for selected data\n",
      "By measure, showing performance (cut-point), in order: optimal, US, UK, USUK, corpus\n",
      "percent correct                    HuLiu: 74.50(0.000); 73.66(0.003); 73.61(0.003); 73.64(0.003); 73.80(0.005)\n",
      "percent correct           LabMT_filtered: 69.64(0.245); 65.79(0.189); 65.35(0.187); 65.54(0.188); 69.57(0.244)\n",
      "percent correct              LexicoderSD: 72.43(0.013); 72.40(0.012); 72.35(0.011); 72.40(0.012); 72.37(0.011)\n",
      "percent correct                     MPQA: 71.01(0.012); 70.73(0.008); 70.73(0.008); 70.73(0.008); 70.97(0.012)\n",
      "percent correct                      NRC: 68.51(0.019); 67.81(0.023); 68.35(0.020); 68.07(0.021); 68.33(0.015)\n",
      "percent correct                    SOCAL: 77.90(0.043); 77.58(0.037); 77.63(0.038); 77.61(0.038); 77.69(0.049)\n",
      "percent correct             SWN_filtered: 68.68(0.007); 66.34(0.001); 66.43(0.001); 66.38(0.001); 68.63(0.007)\n",
      "percent correct                 WordStat: 74.24(0.000); 74.24(0.000); 73.51(-0.002); 73.53(-0.001); 73.52(-0.001)\n",
      "\n",
      "*** Averaging using set of means: US ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 74.95(0.000); cut (mean): 75.29(0.219); cut (opt): 75.35(0.239)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 19652, mean 1.59, max 10.42, stdev 1.20, rating 8.8, length 219.78\n",
      "Label 0 & -ve: nr 17823, mean -1.22, min -14.39, stdev 0.97, rating 2.1, length 236.18\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 7177, mean 0.74, max 5.62, stdev 0.67, rating 2.5, length 218.81\n",
      "Label 1 but -ve: nr 5348, mean -0.73, min -4.77, stdev 0.65, rating 8.5, length 286.52\n",
      "\n",
      "*** Averaging using set of means: UK ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 74.77(0.000); cut (mean): 75.24(0.207); cut (opt): 75.28(0.227)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 19810, mean 1.33, max 8.63, stdev 1.00, rating 8.8, length 220.33\n",
      "Label 0 & -ve: nr 17576, mean -0.99, min -11.84, stdev 0.79, rating 2.1, length 235.86\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 7424, mean 0.62, max 4.66, stdev 0.55, rating 2.5, length 220.15\n",
      "Label 1 but -ve: nr 5190, mean -0.60, min -3.97, stdev 0.54, rating 8.5, length 286.47\n",
      "\n",
      "*** Averaging using set of means: USUK ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 74.87(0.000); cut (mean): 75.27(0.210); cut (opt): 75.29(0.213)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 19732, mean 1.43, max 9.29, stdev 1.07, rating 8.8, length 220.08\n",
      "Label 0 & -ve: nr 17706, mean -1.08, min -12.78, stdev 0.86, rating 2.1, length 236.06\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 7294, mean 0.67, max 5.01, stdev 0.59, rating 2.5, length 219.39\n",
      "Label 1 but -ve: nr 5268, mean -0.65, min -4.26, stdev 0.58, rating 8.5, length 286.41\n",
      "\n",
      "*** Averaging using set of means: corpus ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 75.08(0.000); cut (mean): 75.08(0.000); cut (opt): 75.10(-0.004)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 18203, mean 0.82, max 5.56, stdev 0.64, rating 8.9, length 213.56\n",
      "Label 0 & -ve: nr 19339, mean -0.73, min -7.92, stdev 0.55, rating 2.1, length 237.92\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 5661, mean 0.39, max 2.93, stdev 0.36, rating 2.6, length 208.24\n",
      "Label 1 but -ve: nr 6797, mean -0.44, min -2.87, stdev 0.38, rating 8.5, length 288.95\n",
      "\n",
      "********* Working on jobspec: ('_modsonly', True, ())\n",
      "Working with 25000 negative and 25000 positive texts.\n",
      "\n",
      "Results for selected data\n",
      "By measure, showing performance (cut-point), in order: optimal, US, UK, USUK, corpus\n",
      "percent correct                    HuLiu: 73.91(0.000); 73.47(0.003); 73.46(0.003); 73.48(0.003); 73.45(0.002)\n",
      "percent correct           LabMT_filtered: 69.65(0.207); 68.98(0.189); 68.86(0.187); 68.92(0.188); 69.61(0.208)\n",
      "percent correct              LexicoderSD: 71.77(0.010); 71.57(0.012); 71.70(0.011); 71.63(0.012); 71.71(0.009)\n",
      "percent correct                     MPQA: 69.85(0.011); 69.74(0.008); 69.75(0.008); 69.75(0.008); 69.79(0.011)\n",
      "percent correct                      NRC: 68.89(0.013); 67.60(0.023); 68.20(0.020); 67.96(0.021); 68.88(0.013)\n",
      "percent correct                    SOCAL: 77.47(0.036); 77.40(0.037); 77.34(0.038); 77.36(0.038); 77.36(0.038)\n",
      "percent correct             SWN_filtered: 70.99(-0.005); 69.35(0.001); 69.32(0.001); 69.32(0.001); 70.83(-0.004)\n",
      "percent correct                 WordStat: 72.92(-0.007); 72.68(-0.000); 72.63(-0.002); 72.72(-0.001); 72.89(-0.006)\n",
      "\n",
      "*** Averaging using set of means: US ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 75.29(0.000); cut (mean): 75.50(-0.147); cut (opt): 75.52(-0.154)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 17474, mean 1.40, max 10.08, stdev 1.13, rating 8.9, length 213.78\n",
      "Label 0 & -ve: nr 20174, mean -1.44, min -15.21, stdev 1.06, rating 2.1, length 237.23\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 4826, mean 0.68, max 5.29, stdev 0.64, rating 2.6, length 205.95\n",
      "Label 1 but -ve: nr 7526, mean -0.80, min -5.37, stdev 0.69, rating 8.6, length 281.14\n",
      "\n",
      "*** Averaging using set of means: UK ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 75.27(0.000); cut (mean): 75.45(-0.095); cut (opt): 75.46(-0.093)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 17689, mean 1.17, max 8.35, stdev 0.93, rating 8.9, length 214.40\n",
      "Label 0 & -ve: nr 19945, mean -1.18, min -12.52, stdev 0.87, rating 2.1, length 236.97\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 5055, mean 0.57, max 4.38, stdev 0.53, rating 2.6, length 208.42\n",
      "Label 1 but -ve: nr 7311, mean -0.66, min -4.31, stdev 0.57, rating 8.6, length 281.64\n",
      "\n",
      "*** Averaging using set of means: USUK ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 75.27(0.000); cut (mean): 75.47(-0.116); cut (opt): 75.50(-0.105)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 17573, mean 1.26, max 8.98, stdev 1.00, rating 8.9, length 214.23\n",
      "Label 0 & -ve: nr 20061, mean -1.27, min -13.52, stdev 0.94, rating 2.1, length 237.09\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 4939, mean 0.61, max 4.72, stdev 0.57, rating 2.6, length 207.26\n",
      "Label 1 but -ve: nr 7427, mean -0.71, min -4.70, stdev 0.62, rating 8.6, length 280.99\n",
      "\n",
      "*** Averaging using set of means: corpus ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 75.21(0.000); cut (mean): 75.21(0.000); cut (opt): 75.23(0.005)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 18408, mean 0.80, max 5.56, stdev 0.62, rating 8.8, length 217.03\n",
      "Label 0 & -ve: nr 19200, mean -0.74, min -8.09, stdev 0.56, rating 2.1, length 237.08\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 5800, mean 0.39, max 2.97, stdev 0.36, rating 2.6, length 211.71\n",
      "Label 1 but -ve: nr 6592, mean -0.43, min -2.94, stdev 0.38, rating 8.5, length 281.61\n",
      "\n",
      "********* Working on jobspec: ('_none', False, ())\n",
      "Working with 25000 negative and 25000 positive texts.\n",
      "\n",
      "Results for selected data\n",
      "By measure, showing performance (cut-point), in order: optimal, US, UK, USUK, corpus\n",
      "percent correct                    HuLiu: 74.61(0.000); 73.29(0.003); 73.33(0.003); 73.33(0.003); 73.23(0.005)\n",
      "percent correct           LabMT_filtered: 69.66(0.234); 67.35(0.189); 67.10(0.187); 67.19(0.188); 69.54(0.231)\n",
      "percent correct              LexicoderSD: 71.59(0.008); 71.52(0.012); 71.51(0.011); 71.54(0.012); 71.54(0.011)\n",
      "percent correct                     MPQA: 69.92(0.013); 69.40(0.008); 69.41(0.008); 69.40(0.008); 69.90(0.013)\n",
      "percent correct                      NRC: 67.62(0.018); 66.91(0.023); 67.50(0.020); 67.20(0.021); 67.48(0.016)\n",
      "percent correct                    SOCAL: 77.08(0.046); 76.67(0.037); 76.72(0.038); 76.70(0.038); 77.06(0.052)\n",
      "percent correct             SWN_filtered: 70.37(0.000); 70.11(0.001); 70.07(0.001); 70.08(0.001); 70.28(-0.000)\n",
      "percent correct                 WordStat: 73.66(0.000); 73.66(0.000); 72.45(-0.002); 72.43(-0.001); 73.66(0.000)\n",
      "\n",
      "*** Averaging using set of means: US ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 75.04(0.000); cut (mean): 75.11(0.071); cut (opt): 75.17(0.046)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 18666, mean 1.53, max 10.42, stdev 1.19, rating 8.9, length 216.42\n",
      "Label 0 & -ve: nr 18856, mean -1.31, min -14.39, stdev 1.00, rating 2.1, length 237.78\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 6144, mean 0.73, max 5.62, stdev 0.67, rating 2.6, length 210.98\n",
      "Label 1 but -ve: nr 6334, mean -0.76, min -5.07, stdev 0.67, rating 8.5, length 286.04\n",
      "\n",
      "*** Averaging using set of means: UK ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 74.99(0.000); cut (mean): 75.09(0.087); cut (opt): 75.12(0.095)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 18889, mean 1.28, max 8.63, stdev 0.99, rating 8.8, length 217.24\n",
      "Label 0 & -ve: nr 18606, mean -1.07, min -11.84, stdev 0.83, rating 2.1, length 237.53\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 6394, mean 0.61, max 4.66, stdev 0.55, rating 2.6, length 212.77\n",
      "Label 1 but -ve: nr 6111, mean -0.63, min -4.06, stdev 0.55, rating 8.5, length 286.05\n",
      "\n",
      "*** Averaging using set of means: USUK ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 75.03(0.000); cut (mean): 75.07(0.079); cut (opt): 75.12(0.118)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 18788, mean 1.37, max 9.29, stdev 1.06, rating 8.8, length 216.90\n",
      "Label 0 & -ve: nr 18725, mean -1.16, min -12.78, stdev 0.89, rating 2.1, length 237.74\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 6275, mean 0.65, max 5.01, stdev 0.59, rating 2.6, length 211.66\n",
      "Label 1 but -ve: nr 6212, mean -0.68, min -4.43, stdev 0.60, rating 8.5, length 285.97\n",
      "\n",
      "*** Averaging using set of means: corpus ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 74.80(0.000); cut (mean): 74.80(0.000); cut (opt): 74.86(0.021)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 18189, mean 0.81, max 5.53, stdev 0.64, rating 8.9, length 214.43\n",
      "Label 0 & -ve: nr 19209, mean -0.73, min -7.71, stdev 0.55, rating 2.1, length 238.19\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 5791, mean 0.39, max 2.95, stdev 0.36, rating 2.6, length 207.99\n",
      "Label 1 but -ve: nr 6811, mean -0.43, min -2.77, stdev 0.37, rating 8.5, length 286.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "percent correct - cut (0): 75.04(0.000); cut (mean): 75.11(0.071); cut (opt): 75.17(0.046)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 18666, mean 1.53, max 10.42, stdev 1.19, rating 8.9, length 216.42\n",
      "Label 0 & -ve: nr 18856, mean -1.31, min -14.39, stdev 1.00, rating 2.1, length 237.78\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 6144, mean 0.73, max 5.62, stdev 0.67, rating 2.6, length 210.98\n",
      "Label 1 but -ve: nr 6334, mean -0.76, min -5.07, stdev 0.67, rating 8.5, length 286.04\n",
      "\n",
      "*** Averaging using set of means: UK ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 74.99(0.000); cut (mean): 75.09(0.087); cut (opt): 75.12(0.095)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 18889, mean 1.28, max 8.63, stdev 0.99, rating 8.8, length 217.24\n",
      "Label 0 & -ve: nr 18606, mean -1.07, min -11.84, stdev 0.83, rating 2.1, length 237.53\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 6394, mean 0.61, max 4.66, stdev 0.55, rating 2.6, length 212.77\n",
      "Label 1 but -ve: nr 6111, mean -0.63, min -4.06, stdev 0.55, rating 8.5, length 286.05\n",
      "\n",
      "*** Averaging using set of means: USUK ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 75.03(0.000); cut (mean): 75.07(0.079); cut (opt): 75.12(0.118)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 18788, mean 1.37, max 9.29, stdev 1.06, rating 8.8, length 216.90\n",
      "Label 0 & -ve: nr 18725, mean -1.16, min -12.78, stdev 0.89, rating 2.1, length 237.74\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 6275, mean 0.65, max 5.01, stdev 0.59, rating 2.6, length 211.66\n",
      "Label 1 but -ve: nr 6212, mean -0.68, min -4.43, stdev 0.60, rating 8.5, length 285.97\n",
      "\n",
      "*** Averaging using set of means: corpus ***\n",
      "\n",
      "Averaging across lexica:\n",
      "['HuLiu', 'LabMT_filtered', 'LexicoderSD', 'MPQA', 'NRC', 'SOCAL', 'SWN_filtered', 'WordStat']\n",
      "\n",
      "percent correct - cut (0): 74.80(0.000); cut (mean): 74.80(0.000); cut (opt): 74.86(0.021)\n",
      "\n",
      "Correctly classified items:\n",
      "Label 1 & +ve: nr 18189, mean 0.81, max 5.53, stdev 0.64, rating 8.9, length 214.43\n",
      "Label 0 & -ve: nr 19209, mean -0.73, min -7.71, stdev 0.55, rating 2.1, length 238.19\n",
      "Incorrectly classified items:\n",
      "Label 0 but +ve: nr 5791, mean 0.39, max 2.95, stdev 0.36, rating 2.6, length 207.99\n",
      "Label 1 but -ve: nr 6811, mean -0.43, min -2.77, stdev 0.37, rating 8.5, length 286.48\n"
     ]
    }
   ],
   "source": [
    "nrsetups = len(jobspeclist)\n",
    "nrlex = len(lexnames)\n",
    "\n",
    "supplied_data = [('US', USm, USs),\n",
    "                 ('UK', UKm, UKs),\n",
    "                 ('USUK', USUKm, USUKs)]\n",
    "\n",
    "lexcols2include = list(range(nrlex))\n",
    "\n",
    "for counter, jobspec in enumerate(jobspeclist):\n",
    "    print('\\n********* Working on jobspec:', jobspec)\n",
    "    sentiment_eval.assess_perf(valencefile_combined, supplied_data, nrlex=nrlex,\n",
    "                               firstvalencecol=6 + counter*nrlex, valcol=1, lengthcol=5, ratingscol=3,\n",
    "                               calc_avgs=(lexcols2include,),\n",
    "                               addcorpusmeans=True, calc_optimal=True, lexperf=True, bootstrap=(True if counter == 0 else False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Assess performance in distinguishing within positive & negative rankings\n",
    "\n",
    "The ranking by the review writer is a value from 1 through 10. The imdb corpus includes 1-4 and 7-10. Calculate the mean and standard deviation of each ranking value. These should be distinct, if our system works well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This output is for table 5 in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into arrays, by ranking value\n",
    "valencefile = corpusfilestem + '_rankandvalence.csv'\n",
    "rankingvar = 'rating'\n",
    "valencevar = 'valence'\n",
    "\n",
    "# Read into pandas dataframe (keep only columns of interest)\n",
    "imdb_df = pd.read_csv(valencefile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>polarity</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>testset</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.638066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.028516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.777879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10002</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.445579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10003</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.748028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  polarity  movie_id  rating  testset   valence\n",
       "0   1         0         0       2        1 -0.638066\n",
       "1   2         0     10000       4        1 -0.028516\n",
       "2   3         0     10001       1        1 -1.777879\n",
       "3   4         0     10002       3        1 -1.445579\n",
       "4   5         0     10003       3        1  0.748028"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 1; n = 10122; mean valence: -1.11; std.dev: 1.11\n",
      "Rating: 2; n = 4586; mean valence: -0.88; std.dev: 1.08\n",
      "Rating: 3; n = 4961; mean valence: -0.71; std.dev: 1.04\n",
      "Rating: 4; n = 5331; mean valence: -0.55; std.dev: 1.04\n",
      "Rating: 7; n = 4803; mean valence: 0.27; std.dev: 1.15\n",
      "Rating: 8; n = 5859; mean valence: 0.47; std.dev: 1.22\n",
      "Rating: 9; n = 4607; mean valence: 0.58; std.dev: 1.23\n",
      "Rating: 10; n = 9731; mean valence: 0.73; std.dev: 1.30\n"
     ]
    }
   ],
   "source": [
    "# Averages by ranking\n",
    "groupvalence = {}\n",
    "\n",
    "for groupval, groupdata in imdb_df.groupby(rankingvar):\n",
    "    print('Rating: {}; n = {}; mean valence: {:4.2f}; std.dev: {:4.2f}'.format(\n",
    "        groupval, len(groupdata), groupdata['valence'].mean(), groupdata['valence'].std()))\n",
    "    groupvalence[groupval] = groupdata['valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 1 to 2: t-stat = -11.87; p-value = 0.0000000\n",
      "From 2 to 3: t-stat = -7.81; p-value = 0.0000000\n",
      "From 3 to 4: t-stat = -7.91; p-value = 0.0000000\n",
      "From 7 to 8: t-stat = -8.61; p-value = 0.0000000\n",
      "From 8 to 9: t-stat = -4.67; p-value = 0.0000031\n",
      "From 9 to 10: t-stat = -6.35; p-value = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "\n",
    "adjacentpairs = [(1,2), (2,3), (3,4), (7,8), (8,9), (9,10)]\n",
    "for pair in adjacentpairs: \n",
    "    tstat, pvalue = sp.stats.ttest_ind(groupvalence[pair[0]], groupvalence[pair[1]], equal_var=False)\n",
    "    print('From {} to {}: t-stat = {:5.2f}; p-value = {:.7f}'.format(pair[0], pair[1], tstat, pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
